{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"                              Brain Tumor Detection","metadata":{"id":"8cGss-vsrQJV"}},{"cell_type":"markdown","source":"We collected data from three different sources, One having all the images with differentitaion in one place, others are in no and yes folders seperately.\n\n\n\n1.   Lets read the images using csv , differentiate them into two sub folders.\n2.   After differentitation, we need to dump into the no and yes classes\n     seperately to train the model\n3.   We got anohter source of images mentionly named no and yes tumors.so\n     we can directly copy these into same folder that we have already.\n3.   Mount the folders yes and no from drive, then train the model accordingly.\n\n","metadata":{"id":"qRQJU0cg0z3E"}},{"cell_type":"markdown","source":"Importing Depandencies","metadata":{"id":"1gNZitV3rKRE"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"PowlZkQFrPVk","execution":{"iopub.status.busy":"2023-06-30T04:21:43.086435Z","iopub.execute_input":"2023-06-30T04:21:43.087559Z","iopub.status.idle":"2023-06-30T04:21:43.700627Z","shell.execute_reply.started":"2023-06-30T04:21:43.087524Z","shell.execute_reply":"2023-06-30T04:21:43.699532Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hW4IohAjyMYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob","metadata":{"id":"2BMIStKXrM2x","execution":{"iopub.status.busy":"2023-06-30T04:21:48.100172Z","iopub.execute_input":"2023-06-30T04:21:48.100987Z","iopub.status.idle":"2023-06-30T04:21:48.105038Z","shell.execute_reply.started":"2023-06-30T04:21:48.100949Z","shell.execute_reply":"2023-06-30T04:21:48.104089Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers,models\nimport os\nfrom PIL import Image","metadata":{"id":"E7CCjumGt80F","execution":{"iopub.status.busy":"2023-06-30T04:21:51.003546Z","iopub.execute_input":"2023-06-30T04:21:51.004211Z","iopub.status.idle":"2023-06-30T04:21:51.010583Z","shell.execute_reply.started":"2023-06-30T04:21:51.004163Z","shell.execute_reply":"2023-06-30T04:21:51.009348Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #Data Augumentation\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"id":"mTxEjw3gAyMs","execution":{"iopub.status.busy":"2023-06-30T04:21:53.677610Z","iopub.execute_input":"2023-06-30T04:21:53.678008Z","iopub.status.idle":"2023-06-30T04:21:53.686008Z","shell.execute_reply.started":"2023-06-30T04:21:53.677976Z","shell.execute_reply":"2023-06-30T04:21:53.684553Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPooling2D,GlobalAveragePooling2D, Input, Dropout, LeakyReLU,UpSampling2D, concatenate\nfrom keras.models import load_model, Model\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications import DenseNet121","metadata":{"id":"u1d9WYCn0w5l","execution":{"iopub.status.busy":"2023-06-30T04:21:56.278563Z","iopub.execute_input":"2023-06-30T04:21:56.278988Z","iopub.status.idle":"2023-06-30T04:21:56.286166Z","shell.execute_reply.started":"2023-06-30T04:21:56.278957Z","shell.execute_reply":"2023-06-30T04:21:56.285045Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import shutil","metadata":{"id":"GPLegA830w8B","execution":{"iopub.status.busy":"2023-06-30T04:22:01.180844Z","iopub.execute_input":"2023-06-30T04:22:01.181209Z","iopub.status.idle":"2023-06-30T04:22:01.185747Z","shell.execute_reply.started":"2023-06-30T04:22:01.181167Z","shell.execute_reply":"2023-06-30T04:22:01.184778Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"NnFnhI1o13dg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Importing","metadata":{"id":"kXKJ49bt19KD"}},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Six_V9B0w_h","outputId":"af8e988d-e671-47df-8b33-22167d7e0f25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone \"https://github.com/aswindam/Brain_tumor.git\"","metadata":{"id":"ipdDOCSAo0oZ","execution":{"iopub.status.busy":"2023-06-30T04:37:43.766157Z","iopub.execute_input":"2023-06-30T04:37:43.766868Z","iopub.status.idle":"2023-06-30T04:37:56.444057Z","shell.execute_reply.started":"2023-06-30T04:37:43.766832Z","shell.execute_reply":"2023-06-30T04:37:56.442868Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Cloning into 'Brain_tumor'...\nremote: Enumerating objects: 26512, done.\u001b[K\nremote: Counting objects: 100% (255/255), done.\u001b[K\nremote: Compressing objects: 100% (255/255), done.\u001b[K\nremote: Total 26512 (delta 0), reused 255 (delta 0), pack-reused 26257\u001b[K\nReceiving objects: 100% (26512/26512), 186.38 MiB | 23.29 MiB/s, done.\nResolving deltas: 100% (635/635), done.\nUpdating files: 100% (26823/26823), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir Brain_tumor_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_N_uGghUo0ry","outputId":"4062b622-f8f8-4bdb-d154-2aefb3f0fa43","execution":{"iopub.status.busy":"2023-06-30T04:38:38.691621Z","iopub.execute_input":"2023-06-30T04:38:38.692034Z","iopub.status.idle":"2023-06-30T04:38:39.660822Z","shell.execute_reply.started":"2023-06-30T04:38:38.691994Z","shell.execute_reply":"2023-06-30T04:38:39.659501Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!cp -r Brain_tumor/have_tumor Brain_tumor_dataset/\n!cp -r Brain_tumor/have_tumor_1/* Brain_tumor_dataset/have_tumor/\n!cp -r Brain_tumor/no_tumor Brain_tumor_dataset/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18JlKzVqdxiu","outputId":"8ab867c0-8f80-4e05-8531-390cd77a994f","execution":{"iopub.status.busy":"2023-06-30T04:39:36.826270Z","iopub.execute_input":"2023-06-30T04:39:36.826752Z","iopub.status.idle":"2023-06-30T04:39:41.084716Z","shell.execute_reply.started":"2023-06-30T04:39:36.826715Z","shell.execute_reply":"2023-06-30T04:39:41.083481Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing","metadata":{"id":"CJLGsxRggR98"}},{"cell_type":"code","source":"","metadata":{"colab":{"background_save":true},"id":"LnDTyi3oAl5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the paths to the train and test folders\ntrain_folder = 'Brain_tumor_dataset'\ntest_folder = 'Brain_tumor/Testing'","metadata":{"colab":{"background_save":true},"id":"9iQeZiqDqx0Q","execution":{"iopub.status.busy":"2023-06-30T04:39:57.981655Z","iopub.execute_input":"2023-06-30T04:39:57.982124Z","iopub.status.idle":"2023-06-30T04:39:57.990879Z","shell.execute_reply.started":"2023-06-30T04:39:57.982072Z","shell.execute_reply":"2023-06-30T04:39:57.989739Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_gen = ImageDataGenerator(rescale=1./255)\n\n# Load the images from the train and test folders as arrays\ntrain_data = data_gen.flow_from_directory(train_folder, target_size=(224, 224), batch_size=32, shuffle=False, class_mode='binary')\ntest_data = data_gen.flow_from_directory(test_folder, target_size=(224, 224), batch_size=32, shuffle=False, class_mode='binary')","metadata":{"colab":{"background_save":true},"id":"0MtlOAhRgfYo","outputId":"683280b8-da0b-49a9-8b8c-14cede8b1ee8","execution":{"iopub.status.busy":"2023-06-30T04:40:02.431177Z","iopub.execute_input":"2023-06-30T04:40:02.431598Z","iopub.status.idle":"2023-06-30T04:40:03.637404Z","shell.execute_reply.started":"2023-06-30T04:40:02.431568Z","shell.execute_reply":"2023-06-30T04:40:03.636413Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found 26429 images belonging to 2 classes.\nFound 394 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"colab":{"background_save":true},"id":"uaEHlwGk1dmg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cnnmodelrelu():\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_relu = 'best_model_checkpoint_relu.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath_relu,\n                                          monitor='val_accuracy',\n                                          save_best_only=True,\n                                          mode='max',\n                                          verbose=1)\n\n    print('CNN with relu activation')\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n\n    cnn = model.fit(\n        train_data,\n        steps_per_epoch=train_data.samples // train_data.batch_size,\n        epochs=20,\n        validation_data=test_data,  # Provide validation data\n        validation_steps=test_data.samples // test_data.batch_size,\n        callbacks=[checkpoint_callback]\n    )\n\n    best_model = load_model(checkpoint_filepath_relu)\n    best_accuracy = max(cnn.history['val_accuracy'])\n    print(f\"Best validation accuracy: {best_accuracy} (Epoch {cnn.history['val_accuracy'].index(best_accuracy) + 1})\")\n\n\ncnnmodelrelu()","metadata":{"id":"_ul5pkCD0voL","execution":{"iopub.status.busy":"2023-06-30T04:40:43.807036Z","iopub.execute_input":"2023-06-30T04:40:43.807418Z","iopub.status.idle":"2023-06-30T05:00:07.416854Z","shell.execute_reply.started":"2023-06-30T04:40:43.807388Z","shell.execute_reply":"2023-06-30T05:00:07.415785Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"CNN with relu activation\nEpoch 1/20\n825/825 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.7334\nEpoch 1: val_accuracy improved from -inf to 0.74219, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 64s 64ms/step - loss: 0.6008 - accuracy: 0.7334 - val_loss: 0.6029 - val_accuracy: 0.7422\nEpoch 2/20\n825/825 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.7782\nEpoch 2: val_accuracy improved from 0.74219 to 0.74479, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 51s 61ms/step - loss: 0.4914 - accuracy: 0.7782 - val_loss: 0.6025 - val_accuracy: 0.7448\nEpoch 3/20\n825/825 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.7826\nEpoch 3: val_accuracy improved from 0.74479 to 0.74740, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 54s 66ms/step - loss: 0.5100 - accuracy: 0.7826 - val_loss: 0.5809 - val_accuracy: 0.7474\nEpoch 4/20\n825/825 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8251\nEpoch 4: val_accuracy did not improve from 0.74740\n825/825 [==============================] - 46s 56ms/step - loss: 0.3821 - accuracy: 0.8251 - val_loss: 0.6354 - val_accuracy: 0.6693\nEpoch 5/20\n824/825 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.8562\nEpoch 5: val_accuracy did not improve from 0.74740\n825/825 [==============================] - 46s 56ms/step - loss: 0.3174 - accuracy: 0.8564 - val_loss: 0.5944 - val_accuracy: 0.6875\nEpoch 6/20\n824/825 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.8891\nEpoch 6: val_accuracy improved from 0.74740 to 0.80208, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 45s 55ms/step - loss: 0.2556 - accuracy: 0.8890 - val_loss: 0.4982 - val_accuracy: 0.8021\nEpoch 7/20\n825/825 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9187\nEpoch 7: val_accuracy improved from 0.80208 to 0.85938, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 46s 56ms/step - loss: 0.1927 - accuracy: 0.9187 - val_loss: 0.3586 - val_accuracy: 0.8594\nEpoch 8/20\n824/825 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9472\nEpoch 8: val_accuracy improved from 0.85938 to 0.91667, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 44s 53ms/step - loss: 0.1273 - accuracy: 0.9472 - val_loss: 0.2816 - val_accuracy: 0.9167\nEpoch 9/20\n825/825 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9739\nEpoch 9: val_accuracy did not improve from 0.91667\n825/825 [==============================] - 45s 54ms/step - loss: 0.0683 - accuracy: 0.9739 - val_loss: 0.7016 - val_accuracy: 0.8620\nEpoch 10/20\n825/825 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9848\nEpoch 10: val_accuracy did not improve from 0.91667\n825/825 [==============================] - 47s 57ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 0.4707 - val_accuracy: 0.9167\nEpoch 11/20\n825/825 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9914\nEpoch 11: val_accuracy did not improve from 0.91667\n825/825 [==============================] - 46s 56ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.5574 - val_accuracy: 0.9062\nEpoch 12/20\n825/825 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9911\nEpoch 12: val_accuracy did not improve from 0.91667\n825/825 [==============================] - 44s 53ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.9137 - val_accuracy: 0.8750\nEpoch 13/20\n825/825 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9954\nEpoch 13: val_accuracy improved from 0.91667 to 0.92448, saving model to best_model_checkpoint_relu.h5\n825/825 [==============================] - 46s 55ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.5835 - val_accuracy: 0.9245\nEpoch 14/20\n825/825 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9957\nEpoch 14: val_accuracy did not improve from 0.92448\n825/825 [==============================] - 50s 60ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 1.1620 - val_accuracy: 0.8672\nEpoch 15/20\n824/825 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978\nEpoch 15: val_accuracy did not improve from 0.92448\n825/825 [==============================] - 45s 55ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.9922 - val_accuracy: 0.8724\nEpoch 16/20\n825/825 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9970\nEpoch 16: val_accuracy did not improve from 0.92448\n825/825 [==============================] - 46s 55ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.1126 - val_accuracy: 0.8880\nEpoch 17/20\n824/825 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9933\nEpoch 17: val_accuracy did not improve from 0.92448\n825/825 [==============================] - 45s 54ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.0743 - val_accuracy: 0.8932\n825/825 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9956\nEpoch 20: val_accuracy did not improve from 0.92448\n825/825 [==============================] - 48s 58ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.6612 - val_accuracy: 0.9036\nBest validation accuracy: 0.9244791865348816 (Epoch 13)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"nUOg8ccyJXRo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"CNN - Activation FN Leaky Relu","metadata":{"id":"DHw-aam-7_uz"}},{"cell_type":"code","source":"def cnnmodelleakyr():\n\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_leaky = 'best_model_checkpoint_leakyrelu.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath_leaky,\n                                          monitor='val_accuracy',\n                                          save_best_only=True,\n                                          mode='max',\n                                          verbose=1)\n\n    print('CNN with Leaky Relu...')\n    # Create the model\n    model1 = Sequential()\n    model1.add(Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.2), input_shape=(224, 224, 3)))\n    model1.add(MaxPooling2D((2, 2)))\n    model1.add(Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.2)))\n    model1.add(MaxPooling2D((2, 2)))\n    model1.add(Conv2D(128, (3, 3), activation=LeakyReLU(alpha=0.2)))\n    model1.add(MaxPooling2D((2, 2)))\n    model1.add(Conv2D(256, (3, 3), activation=LeakyReLU(alpha=0.2)))\n    model1.add(MaxPooling2D((2, 2)))\n    model1.add(Flatten())\n    model1.add(Dense(128, activation='relu'))\n    model1.add(Dense(1, activation='sigmoid'))\n\n    # Compile the model\n    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model with the checkpoint callback\n    leak = model1.fit(\n        train_data,\n        steps_per_epoch=train_data.samples // train_data.batch_size,\n        epochs=20,\n        validation_data=test_data,  # Provide validation data\n        validation_steps=test_data.samples // test_data.batch_size,\n        callbacks=[checkpoint_callback]  # Add the checkpoint callback to the training\n\n    )\n\n    # Load the best model based on validation accuracy\n    best_model = load_model(checkpoint_filepath_leaky)\n    best_accuracy = max(leak.history['val_accuracy'])\n    print(f\"Best validation accuracy: {best_accuracy} (Epoch {leak.history['val_accuracy'].index(best_accuracy) + 1})\")\n\n\ncnnmodelleakyr()","metadata":{"id":"wRETYzVtgfbg","execution":{"iopub.status.busy":"2023-06-30T05:02:13.301228Z","iopub.execute_input":"2023-06-30T05:02:13.301985Z","iopub.status.idle":"2023-06-30T05:23:49.423940Z","shell.execute_reply.started":"2023-06-30T05:02:13.301948Z","shell.execute_reply":"2023-06-30T05:23:49.422895Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CNN with Leaky Relu...\nEpoch 1/20\n825/825 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.6920\nEpoch 1: val_accuracy improved from -inf to 0.74479, saving model to best_model_checkpoint_leakyrelu.h5\n825/825 [==============================] - 58s 67ms/step - loss: 0.6678 - accuracy: 0.6920 - val_loss: 0.6777 - val_accuracy: 0.7448\nEpoch 2/20\n825/825 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.7564\nEpoch 2: val_accuracy improved from 0.74479 to 0.74740, saving model to best_model_checkpoint_leakyrelu.h5\n825/825 [==============================] - 54s 65ms/step - loss: 0.5219 - accuracy: 0.7564 - val_loss: 0.6088 - val_accuracy: 0.7474\nEpoch 3/20\n825/825 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.7747\nEpoch 3: val_accuracy did not improve from 0.74740\n825/825 [==============================] - 54s 65ms/step - loss: 0.4761 - accuracy: 0.7747 - val_loss: 0.6559 - val_accuracy: 0.7292\nEpoch 4/20\n825/825 [==============================] - ETA: 0s - loss: 2.5211 - accuracy: 0.7445\nEpoch 4: val_accuracy improved from 0.74740 to 0.75260, saving model to best_model_checkpoint_leakyrelu.h5\n825/825 [==============================] - 54s 65ms/step - loss: 2.5211 - accuracy: 0.7445 - val_loss: 0.6531 - val_accuracy: 0.7526\nEpoch 5/20\n825/825 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.5638\nEpoch 5: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6798 - accuracy: 0.5638 - val_loss: 0.6506 - val_accuracy: 0.7526\nEpoch 6/20\n825/825 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5373\nEpoch 6: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6907 - accuracy: 0.5373 - val_loss: 0.6527 - val_accuracy: 0.7526\nEpoch 7/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 7: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6553 - val_accuracy: 0.7526\nEpoch 8/20\n825/825 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.5361\nEpoch 8: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6909 - accuracy: 0.5361 - val_loss: 0.6571 - val_accuracy: 0.7526\nEpoch 9/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 9: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6563 - val_accuracy: 0.7526\nEpoch 10/20\n825/825 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5361\nEpoch 10: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6583 - val_accuracy: 0.7526\nEpoch 11/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 11: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6585 - val_accuracy: 0.7526\nEpoch 12/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 12: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6593 - val_accuracy: 0.7526\nEpoch 13/20\n825/825 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5361\nEpoch 13: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6594 - val_accuracy: 0.7526\nEpoch 14/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 14: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6585 - val_accuracy: 0.7526\nEpoch 15/20\n825/825 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5361\nEpoch 15: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6580 - val_accuracy: 0.7526\nEpoch 16/20\n825/825 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5361\nEpoch 16: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 52s 63ms/step - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6580 - val_accuracy: 0.7526\nEpoch 17/20\n825/825 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5361\nEpoch 17: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6907 - accuracy: 0.5361 - val_loss: 0.6597 - val_accuracy: 0.7526\nEpoch 18/20\n825/825 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5361\nEpoch 18: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6907 - accuracy: 0.5361 - val_loss: 0.6599 - val_accuracy: 0.7526\nEpoch 19/20\n825/825 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5373\nEpoch 19: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 52s 63ms/step - loss: 0.6905 - accuracy: 0.5373 - val_loss: 0.6585 - val_accuracy: 0.7526\nEpoch 20/20\n825/825 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5373\nEpoch 20: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 53s 64ms/step - loss: 0.6906 - accuracy: 0.5373 - val_loss: 0.6575 - val_accuracy: 0.7526\nBest validation accuracy: 0.7526041865348816 (Epoch 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"0N7PEMwIea8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying VGG16","metadata":{"id":"bpmaR3hp7sfJ"}},{"cell_type":"code","source":"def vgg():\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_vgg = 'best_model_checkpoint_vgg.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback_vgg = ModelCheckpoint(filepath=checkpoint_filepath_vgg,\n                                          monitor='val_accuracy',\n                                          save_best_only=True,\n                                          mode='max',\n                                          verbose=1)\n    print('Classification using VGG')\n\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    vggmodel = Sequential()\n    vggmodel.add(base_model)\n    vggmodel.add(Flatten())\n    vggmodel.add(Dense(4096, activation=LeakyReLU(alpha=0.2)))\n    vggmodel.add(Dense(4096, activation=LeakyReLU(alpha=0.2)))\n    vggmodel.add(Dense(1, activation='sigmoid'))\n    vggmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model with the checkpoint callback\n    vggm = vggmodel.fit(\n        train_data,\n        steps_per_epoch=train_data.samples // train_data.batch_size,\n        epochs=10,\n        validation_data=test_data,  # Provide validation data\n        validation_steps=test_data.samples // test_data.batch_size,\n        callbacks=[checkpoint_callback_vgg]  # Add the checkpoint callback to the training\n\n    )\n\n    # Load the best model based on validation accuracy\n    best_model = load_model(checkpoint_filepath_vgg)\n    best_accuracy = max(vggm.history['val_accuracy'])\n    print(f\"Best validation accuracy: {best_accuracy} (Epoch {vggm.history['val_accuracy'].index(best_accuracy) + 1})\")\n\nvgg()","metadata":{"id":"J69wqFoPgffF","execution":{"iopub.status.busy":"2023-06-30T05:49:48.079324Z","iopub.execute_input":"2023-06-30T05:49:48.080393Z","iopub.status.idle":"2023-06-30T06:48:50.112823Z","shell.execute_reply.started":"2023-06-30T05:49:48.080344Z","shell.execute_reply":"2023-06-30T06:48:50.111070Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Classification using VGG\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\nEpoch 1/10\n825/825 [==============================] - ETA: 0s - loss: 9.8550 - accuracy: 0.5222\nEpoch 1: val_accuracy improved from -inf to 0.75260, saving model to best_model_checkpoint_vgg.h5\n825/825 [==============================] - 361s 416ms/step - loss: 9.8550 - accuracy: 0.5222 - val_loss: 0.6117 - val_accuracy: 0.7526\nEpoch 2/10\n825/825 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.5094\nEpoch 2: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 325s 394ms/step - loss: 0.7008 - accuracy: 0.5094 - val_loss: 0.6329 - val_accuracy: 0.7526\nEpoch 3/10\n825/825 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.5202\nEpoch 3: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 324s 393ms/step - loss: 0.7032 - accuracy: 0.5202 - val_loss: 0.6305 - val_accuracy: 0.7526\nEpoch 4/10\n825/825 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.5215\nEpoch 4: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 325s 394ms/step - loss: 0.6991 - accuracy: 0.5215 - val_loss: 0.6345 - val_accuracy: 0.7526\nEpoch 5/10\n825/825 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.4997\nEpoch 5: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 325s 393ms/step - loss: 0.6988 - accuracy: 0.4997 - val_loss: 0.6768 - val_accuracy: 0.7526\nEpoch 6/10\n825/825 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.5257\nEpoch 6: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 325s 393ms/step - loss: 0.6980 - accuracy: 0.5257 - val_loss: 0.6502 - val_accuracy: 0.7526\nEpoch 7/10\n825/825 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5343\nEpoch 7: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 323s 392ms/step - loss: 0.6958 - accuracy: 0.5343 - val_loss: 0.6865 - val_accuracy: 0.7526\nEpoch 8/10\n825/825 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5276\nEpoch 8: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 325s 393ms/step - loss: 0.6958 - accuracy: 0.5276 - val_loss: 0.6257 - val_accuracy: 0.7526\nEpoch 9/10\n825/825 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.5143\nEpoch 9: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 324s 392ms/step - loss: 0.6966 - accuracy: 0.5143 - val_loss: 0.6530 - val_accuracy: 0.7526\nEpoch 10/10\n825/825 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5070\nEpoch 10: val_accuracy did not improve from 0.75260\n825/825 [==============================] - 324s 393ms/step - loss: 0.6951 - accuracy: 0.5070 - val_loss: 0.6507 - val_accuracy: 0.7526\nBest validation accuracy: 0.7526041865348816 (Epoch 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"VM-JWb3n7kPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"4uZ-xKS9PCAZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ResNet","metadata":{"id":"CLH-CgcU8E-A"}},{"cell_type":"code","source":"def resnetm():\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_resnet = 'best_model_checkpoint_resnet.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback_resnet = ModelCheckpoint(filepath=checkpoint_filepath_resnet,\n                                                 monitor='val_accuracy',\n                                                 save_best_only=True,\n                                                 mode='max',\n                                                 verbose=1)\n\n    print('Classification using ResNet')\n\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    resnet_model = GlobalAveragePooling2D()(base_model.output)\n    resnet_model = Dense(256, activation='relu')(resnet_model)\n    predictions = Dense(1, activation='sigmoid')(resnet_model)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model with the checkpoint callback\n    history = model.fit(\n        train_data,\n        epochs=20,\n        batch_size=20,\n        validation_data=test_data,\n        callbacks=[checkpoint_callback_resnet]\n    )\n\n    # Load the best model based on validation accuracy\n    best_model = load_model(checkpoint_filepath_resnet)\n    best_accuracy = max(history.history['val_accuracy'])\n    print(\n        f\"Best validation accuracy: {best_accuracy} (Epoch {history.history['val_accuracy'].index(best_accuracy) + 1})\")\n\nresnetm()","metadata":{"id":"BqznhxLjLiFs","execution":{"iopub.status.busy":"2023-06-30T06:48:55.295718Z","iopub.execute_input":"2023-06-30T06:48:55.296099Z","iopub.status.idle":"2023-06-30T08:24:19.598821Z","shell.execute_reply.started":"2023-06-30T06:48:55.296068Z","shell.execute_reply":"2023-06-30T08:24:19.597517Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Classification using ResNet\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 1s 0us/step\nEpoch 1/20\n826/826 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7971\nEpoch 1: val_accuracy improved from -inf to 0.30457, saving model to best_model_checkpoint_resnet.h5\n826/826 [==============================] - 318s 335ms/step - loss: 0.5019 - accuracy: 0.7971 - val_loss: 0.8459 - val_accuracy: 0.3046\nEpoch 2/20\n826/826 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9492\nEpoch 2: val_accuracy improved from 0.30457 to 0.67766, saving model to best_model_checkpoint_resnet.h5\n826/826 [==============================] - 272s 330ms/step - loss: 0.1760 - accuracy: 0.9492 - val_loss: 0.9066 - val_accuracy: 0.6777\nEpoch 3/20\n826/826 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9569\nEpoch 3: val_accuracy improved from 0.67766 to 0.73350, saving model to best_model_checkpoint_resnet.h5\n826/826 [==============================] - 272s 329ms/step - loss: 0.1500 - accuracy: 0.9569 - val_loss: 1.6328 - val_accuracy: 0.7335\nEpoch 4/20\n826/826 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9729\nEpoch 4: val_accuracy improved from 0.73350 to 0.76396, saving model to best_model_checkpoint_resnet.h5\n826/826 [==============================] - 272s 329ms/step - loss: 0.1024 - accuracy: 0.9729 - val_loss: 0.9087 - val_accuracy: 0.7640\nEpoch 5/20\n826/826 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9690\nEpoch 5: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 271s 328ms/step - loss: 0.1002 - accuracy: 0.9690 - val_loss: 2.1464 - val_accuracy: 0.7335\nEpoch 6/20\n826/826 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9751\nEpoch 6: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 1.3353 - val_accuracy: 0.5508\nEpoch 7/20\n826/826 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9782\nEpoch 7: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 271s 328ms/step - loss: 0.0673 - accuracy: 0.9782 - val_loss: 3.1963 - val_accuracy: 0.3325\nEpoch 8/20\n826/826 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9810\nEpoch 8: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 272s 329ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.9595 - val_accuracy: 0.7284\nEpoch 9/20\n826/826 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9776\nEpoch 9: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 271s 328ms/step - loss: 0.0626 - accuracy: 0.9776 - val_loss: 0.8241 - val_accuracy: 0.6472\nEpoch 10/20\n826/826 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9903\nEpoch 10: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 271s 328ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 1.3570 - val_accuracy: 0.4822\nEpoch 11/20\n826/826 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9888\nEpoch 11: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 271s 327ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.8357 - val_accuracy: 0.7107\nEpoch 12/20\n826/826 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9886\nEpoch 12: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.7723 - val_accuracy: 0.7081\nEpoch 13/20\n826/826 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9926\nEpoch 13: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.8295 - val_accuracy: 0.6447\nEpoch 14/20\n826/826 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9902\nEpoch 14: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0316 - accuracy: 0.9902 - val_loss: 0.9368 - val_accuracy: 0.5330\nEpoch 15/20\n826/826 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949\nEpoch 15: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 1.1782 - val_accuracy: 0.6015\nEpoch 16/20\n826/826 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9940\nEpoch 16: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 1.7949 - val_accuracy: 0.4036\nEpoch 17/20\n826/826 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9950\nEpoch 17: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.8157 - val_accuracy: 0.6929\nEpoch 18/20\n826/826 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\nEpoch 18: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 1.4586 - val_accuracy: 0.6345\nEpoch 19/20\n826/826 [==============================] - ETA: 0s - loss: 3.2324e-04 - accuracy: 0.9999\nEpoch 19: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 3.2324e-04 - accuracy: 0.9999 - val_loss: 0.8859 - val_accuracy: 0.6904\nEpoch 20/20\n826/826 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9964\nEpoch 20: val_accuracy did not improve from 0.76396\n826/826 [==============================] - 270s 327ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 1.0199 - val_accuracy: 0.6168\nBest validation accuracy: 0.7639594078063965 (Epoch 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"EceUgjgSEVQt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inception","metadata":{"id":"Um_CHb7JGbUo"}},{"cell_type":"code","source":"def inceptionv3():\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_inception = 'best_model_checkpoint_inception.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback_inception = ModelCheckpoint(filepath=checkpoint_filepath_inception,\n                                                    monitor='val_accuracy',\n                                                    save_best_only=True,\n                                                    mode='max',\n                                                    verbose=1)\n\n    print('Classification using InceptionV3')\n\n    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    inception_model = GlobalAveragePooling2D()(base_model.output)\n    inception_model = Dense(256, activation='relu')(inception_model)\n    predictions = Dense(1, activation='sigmoid')(inception_model)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model with the checkpoint callback\n    history = model.fit(\n        train_data,\n        epochs=20,\n        batch_size=20,\n        validation_data=test_data,\n        callbacks=[checkpoint_callback_inception]\n    )\n\n    # Load the best model based on validation accuracy\n    best_model = load_model(checkpoint_filepath_inception)\n    best_accuracy = max(history.history['val_accuracy'])\n    print(\n        f\"Best validation accuracy: {best_accuracy} (Epoch {history.history['val_accuracy'].index(best_accuracy) + 1})\")\n\ninceptionv3()\n","metadata":{"id":"fKICYpeiGcE7","execution":{"iopub.status.busy":"2023-06-30T08:24:19.603859Z","iopub.execute_input":"2023-06-30T08:24:19.605953Z","iopub.status.idle":"2023-06-30T09:29:49.808920Z","shell.execute_reply.started":"2023-06-30T08:24:19.605919Z","shell.execute_reply":"2023-06-30T09:29:49.807860Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Classification using InceptionV3\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 0s 0us/step\nEpoch 1/20\n826/826 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.5306\nEpoch 1: val_accuracy improved from -inf to 0.36041, saving model to best_model_checkpoint_inception.h5\n826/826 [==============================] - 243s 241ms/step - loss: 0.6852 - accuracy: 0.5306 - val_loss: 0.6967 - val_accuracy: 0.3604\nEpoch 2/20\n826/826 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.5352\nEpoch 2: val_accuracy improved from 0.36041 to 0.73350, saving model to best_model_checkpoint_inception.h5\n826/826 [==============================] - 190s 231ms/step - loss: 0.6836 - accuracy: 0.5352 - val_loss: 0.6360 - val_accuracy: 0.7335\nEpoch 3/20\n826/826 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.7140\nEpoch 3: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 189s 229ms/step - loss: 0.5478 - accuracy: 0.7140 - val_loss: 0.5944 - val_accuracy: 0.7335\nEpoch 4/20\n826/826 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8449\nEpoch 4: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.3789 - accuracy: 0.8449 - val_loss: 0.6811 - val_accuracy: 0.6117\nEpoch 5/20\n826/826 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9115\nEpoch 5: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.2304 - accuracy: 0.9115 - val_loss: 1.5660 - val_accuracy: 0.5990\nEpoch 6/20\n826/826 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9137\nEpoch 6: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 229ms/step - loss: 0.2404 - accuracy: 0.9137 - val_loss: 7.3248 - val_accuracy: 0.4949\nEpoch 7/20\n826/826 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9533\nEpoch 7: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 189s 229ms/step - loss: 0.1566 - accuracy: 0.9533 - val_loss: 0.9698 - val_accuracy: 0.3122\nEpoch 8/20\n826/826 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9585\nEpoch 8: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.1238 - accuracy: 0.9585 - val_loss: 1.0969 - val_accuracy: 0.6066\nEpoch 9/20\n826/826 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9687\nEpoch 9: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0969 - accuracy: 0.9687 - val_loss: 0.8928 - val_accuracy: 0.5787\nEpoch 10/20\n826/826 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9627\nEpoch 10: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.1241 - accuracy: 0.9627 - val_loss: 0.8747 - val_accuracy: 0.5888\nEpoch 11/20\n826/826 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9759\nEpoch 11: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0751 - accuracy: 0.9759 - val_loss: 0.6131 - val_accuracy: 0.6980\nEpoch 12/20\n826/826 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9841\nEpoch 12: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0589 - accuracy: 0.9841 - val_loss: 0.9473 - val_accuracy: 0.5939\nEpoch 13/20\n826/826 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9805\nEpoch 13: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0563 - accuracy: 0.9805 - val_loss: 0.6549 - val_accuracy: 0.7081\nEpoch 14/20\n826/826 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9895\nEpoch 14: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 191s 231ms/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.7468 - val_accuracy: 0.6751\nEpoch 15/20\n826/826 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9820\nEpoch 15: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 0.7294 - val_accuracy: 0.5711\nEpoch 16/20\n826/826 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9861\nEpoch 16: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0346 - accuracy: 0.9861 - val_loss: 0.8754 - val_accuracy: 0.6878\nEpoch 17/20\n826/826 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9743\nEpoch 17: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0692 - accuracy: 0.9743 - val_loss: 0.6553 - val_accuracy: 0.7132\nEpoch 18/20\n826/826 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9775\nEpoch 18: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0412 - accuracy: 0.9775 - val_loss: 2.1820 - val_accuracy: 0.3122\nEpoch 19/20\n826/826 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9902\nEpoch 19: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0246 - accuracy: 0.9902 - val_loss: 0.6002 - val_accuracy: 0.7157\nEpoch 20/20\n826/826 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9939\nEpoch 20: val_accuracy did not improve from 0.73350\n826/826 [==============================] - 190s 230ms/step - loss: 0.0310 - accuracy: 0.9939 - val_loss: 0.7029 - val_accuracy: 0.5761\nBest validation accuracy: 0.7335025668144226 (Epoch 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"id":"IjA_TLtXGfdA"}},{"cell_type":"markdown","source":"Dense Net","metadata":{"id":"eoJ6b0FsGlx7"}},{"cell_type":"code","source":"def densenet121():\n\n    # Define the checkpoint filepath\n    checkpoint_filepath_densenet = 'best_model_checkpoint_densenet.h5'\n\n    # Create the ModelCheckpoint callback\n    checkpoint_callback_densenet = ModelCheckpoint(filepath=checkpoint_filepath_densenet,\n                                                   monitor='val_accuracy',\n                                                   save_best_only=True,\n                                                   mode='max',\n                                                   verbose=1)\n\n    print('Classification using DenseNet121')\n\n    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    densenet_model = GlobalAveragePooling2D()(base_model.output)\n    densenet_model = Dense(256, activation='relu')(densenet_model)\n    predictions = Dense(1, activation='sigmoid')(densenet_model)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model with the checkpoint callback\n    history = model.fit(\n        train_data,\n        epochs=20,\n        batch_size=20,\n        validation_data=test_data,\n        callbacks=[checkpoint_callback_densenet]\n    )\n\n    # Load the best model based on validation accuracy\n    best_model = load_model(checkpoint_filepath_densenet)\n    best_accuracy = max(history.history['val_accuracy'])\n    print(\n        f\"Best validation accuracy: {best_accuracy} (Epoch {history.history['val_accuracy'].index(best_accuracy) + 1})\")\n\ndensenet121()\n","metadata":{"id":"mJpTCUtVGnUu","execution":{"iopub.status.busy":"2023-06-30T09:29:49.811536Z","iopub.execute_input":"2023-06-30T09:29:49.812159Z","iopub.status.idle":"2023-06-30T11:10:52.895423Z","shell.execute_reply.started":"2023-06-30T09:29:49.812121Z","shell.execute_reply":"2023-06-30T11:10:52.894280Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Classification using DenseNet121\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29084464/29084464 [==============================] - 0s 0us/step\nEpoch 1/20\n826/826 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.7893\nEpoch 1: val_accuracy improved from -inf to 0.72081, saving model to best_model_checkpoint_densenet.h5\n826/826 [==============================] - 372s 361ms/step - loss: 0.4378 - accuracy: 0.7893 - val_loss: 1.0990 - val_accuracy: 0.7208\nEpoch 2/20\n826/826 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9449\nEpoch 2: val_accuracy did not improve from 0.72081\n826/826 [==============================] - 287s 348ms/step - loss: 0.1776 - accuracy: 0.9449 - val_loss: 0.8579 - val_accuracy: 0.6320\nEpoch 3/20\n826/826 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9654\nEpoch 3: val_accuracy improved from 0.72081 to 0.73604, saving model to best_model_checkpoint_densenet.h5\n826/826 [==============================] - 289s 349ms/step - loss: 0.1283 - accuracy: 0.9654 - val_loss: 0.5559 - val_accuracy: 0.7360\nEpoch 4/20\n826/826 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9686\nEpoch 4: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 287s 347ms/step - loss: 0.1147 - accuracy: 0.9686 - val_loss: 3.1349 - val_accuracy: 0.2995\nEpoch 5/20\n826/826 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9739\nEpoch 5: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 347ms/step - loss: 0.0993 - accuracy: 0.9739 - val_loss: 1.5313 - val_accuracy: 0.4543\nEpoch 6/20\n826/826 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9743\nEpoch 6: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 347ms/step - loss: 0.0926 - accuracy: 0.9743 - val_loss: 0.8715 - val_accuracy: 0.6294\nEpoch 7/20\n826/826 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9726\nEpoch 7: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 347ms/step - loss: 0.1005 - accuracy: 0.9726 - val_loss: 2.4689 - val_accuracy: 0.2919\nEpoch 8/20\n826/826 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9787\nEpoch 8: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 347ms/step - loss: 0.0860 - accuracy: 0.9787 - val_loss: 1.0651 - val_accuracy: 0.5736\nEpoch 9/20\n826/826 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9753\nEpoch 9: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 346ms/step - loss: 0.0908 - accuracy: 0.9753 - val_loss: 2.6357 - val_accuracy: 0.2843\nEpoch 10/20\n826/826 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9801\nEpoch 10: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 346ms/step - loss: 0.0705 - accuracy: 0.9801 - val_loss: 5.6815 - val_accuracy: 0.2716\nEpoch 11/20\n826/826 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9739\nEpoch 11: val_accuracy did not improve from 0.73604\n826/826 [==============================] - 286s 346ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 2.0850 - val_accuracy: 0.2792\nEpoch 12/20\n826/826 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9823\nEpoch 12: val_accuracy improved from 0.73604 to 0.73858, saving model to best_model_checkpoint_densenet.h5\n826/826 [==============================] - 286s 347ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.7658 - val_accuracy: 0.7386\nEpoch 13/20\n826/826 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9904\nEpoch 13: val_accuracy did not improve from 0.73858\n826/826 [==============================] - 285s 345ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.8167 - val_accuracy: 0.6472\nEpoch 14/20\n826/826 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9860\nEpoch 14: val_accuracy did not improve from 0.73858\n826/826 [==============================] - 286s 346ms/step - loss: 0.0392 - accuracy: 0.9860 - val_loss: 1.9799 - val_accuracy: 0.4213\nEpoch 15/20\n826/826 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9864\nEpoch 15: val_accuracy improved from 0.73858 to 0.76650, saving model to best_model_checkpoint_densenet.h5\n826/826 [==============================] - 286s 346ms/step - loss: 0.0409 - accuracy: 0.9864 - val_loss: 0.6721 - val_accuracy: 0.7665\nEpoch 16/20\n826/826 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9902\nEpoch 16: val_accuracy did not improve from 0.76650\n826/826 [==============================] - 284s 344ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 1.4215 - val_accuracy: 0.4873\nEpoch 17/20\n826/826 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9796\nEpoch 17: val_accuracy did not improve from 0.76650\n826/826 [==============================] - 284s 344ms/step - loss: 0.0761 - accuracy: 0.9796 - val_loss: 3.9318 - val_accuracy: 0.2716\nEpoch 18/20\n826/826 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9897\nEpoch 18: val_accuracy did not improve from 0.76650\n826/826 [==============================] - 284s 344ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 2.2587 - val_accuracy: 0.2817\nEpoch 19/20\n826/826 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9904\nEpoch 19: val_accuracy did not improve from 0.76650\n826/826 [==============================] - 284s 344ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 10.1379 - val_accuracy: 0.2843\nEpoch 20/20\n826/826 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9862\nEpoch 20: val_accuracy did not improve from 0.76650\n826/826 [==============================] - 284s 344ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 3.5096 - val_accuracy: 0.2589\nBest validation accuracy: 0.7664974331855774 (Epoch 15)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing using image downloaded from net..","metadata":{}},{"cell_type":"markdown","source":"","metadata":{"id":"rGXThSd0Gq6t"}},{"cell_type":"code","source":"image_path1 = '/kaggle/input/datase/test 1.jpg'\nimage1 = Image.open(image_path1)\nimage1 = image1.resize((224, 224))  # Resize the image to match the input size of your model\nimage1 = np.array(image1)  # Convert image to numpy array\nimage1 = image1 / 255.0  # Normalize the image\n\nimage_path2 = '/kaggle/input/testprede/test 2.jpg'\nimage2 = Image.open(image_path2)\nimage2 = image2.resize((224, 224))  # Resize the image to match the input size of your model\nimage2 = np.array(image2)  # Convert image to numpy array\nimage2 = image2 / 255.0  # Normalize the image\n\nimage_path3 = '/kaggle/input/test3img/test 3.jpg'\nimage3 = Image.open(image_path3)\nimage3 = image3.resize((224, 224))  # Resize the image to match the input size of your model\nimage3 = np.array(image3)  # Convert image to numpy array\nimage3 = image3 / 255.0  # Normalize the image\n\n\n# Load the model from the HDF5 file\nmodel_path = '/kaggle/working/best_model_checkpoint_relu.h5'\nmodel = tf.keras.models.load_model(model_path)","metadata":{"id":"QLb3lPvoNBpe","execution":{"iopub.status.busy":"2023-06-30T11:48:14.441789Z","iopub.execute_input":"2023-06-30T11:48:14.442161Z","iopub.status.idle":"2023-06-30T11:48:15.124959Z","shell.execute_reply.started":"2023-06-30T11:48:14.442129Z","shell.execute_reply":"2023-06-30T11:48:15.123876Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"input_data1 = np.expand_dims(image1, axis=0)  # Adding an extra dimension for batch\npredictions1 = model.predict(input_data1)\n\n# Interpret the results\nclass_names = ['no_tumor', 'have_tumor']  # Define your class names\npredicted_class_index1 = np.argmax(predictions1)\npredicted_class1 = class_names[predicted_class_index1]\nconfidence1 = predictions1[0][predicted_class_index1]\n\nprint('Prediction for image 1:', predicted_class1)\nprint('Confidence that model did predict is :', confidence1*100)","metadata":{"id":"Yv8xhBzzNe8e","execution":{"iopub.status.busy":"2023-06-30T11:48:40.835524Z","iopub.execute_input":"2023-06-30T11:48:40.835901Z","iopub.status.idle":"2023-06-30T11:48:40.979021Z","shell.execute_reply.started":"2023-06-30T11:48:40.835872Z","shell.execute_reply":"2023-06-30T11:48:40.977606Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 77ms/step\nPrediction for image 1: no_tumor\nConfidence that model did predict is : 21.08895182609558\n","output_type":"stream"}]},{"cell_type":"code","source":"# Making predictions for image 2\ninput_data2 = np.expand_dims(image2, axis=0)  # Adding an extra dimension for batch\npredictions2 = model.predict(input_data2)\n\n# Interpret the results\npredicted_class_index2 = np.argmax(predictions2)\npredicted_class2 = class_names[predicted_class_index2]\nconfidence2 = predictions2[0][predicted_class_index2]\n\nprint('Prediction for image 2 ---', predicted_class2)\nprint('Confidence that model did predict is :', confidence2 * 100)","metadata":{"id":"0CLNCl0vN8Pm","execution":{"iopub.status.busy":"2023-06-30T11:49:28.212503Z","iopub.execute_input":"2023-06-30T11:49:28.212934Z","iopub.status.idle":"2023-06-30T11:49:28.284447Z","shell.execute_reply.started":"2023-06-30T11:49:28.212886Z","shell.execute_reply":"2023-06-30T11:49:28.283407Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 20ms/step\nPrediction for image 2 --- no_tumor\nConfidence that model did predict is : 99.99998807907104\n","output_type":"stream"}]},{"cell_type":"code","source":"# Making predictions for image 2\ninput_data3 = np.expand_dims(image3, axis=0)  # Adding an extra dimension for batch\npredictions3 = model.predict(input_data3)\n\n# Interpret the results\npredicted_class_index3 = np.argmax(predictions3)\npredicted_class3 = class_names[predicted_class_index3]\nconfidence3 = predictions3[0][predicted_class_index3]\n\nprint('Prediction for image 3:', predicted_class3)\nprint('Confidence that model did predict is :', confidence3 * 100)\n","metadata":{"id":"W0Fr3wolO21d","execution":{"iopub.status.busy":"2023-06-30T11:49:35.844267Z","iopub.execute_input":"2023-06-30T11:49:35.845058Z","iopub.status.idle":"2023-06-30T11:49:35.928977Z","shell.execute_reply.started":"2023-06-30T11:49:35.845023Z","shell.execute_reply":"2023-06-30T11:49:35.927620Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 23ms/step\nPrediction for image 3: no_tumor\nConfidence that model did predict is : 0.16265135491266847\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"zLfeOYj_PUIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lqq0VPapPxbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"stoMEMf3QOuZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"84Ep_hAkQsBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"MOKy1WxWRJUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"zIKyR3iSRmnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8NyUxINbSD6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"6NevUXKpShNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"JeLtC_EIS-gc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ajj5H36mTbzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Mo1kVaSHT5Gc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3rQ1SYFGUWZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"CKO5ZuNPMkWn"},"execution_count":null,"outputs":[]}]}